# Remote Pentesting Architecture
_By David Cannan_

# Quick install
```bash
make run
```

## Project Summary
This project is a work-in-progress and aims to build a scalable, serverless pentesting infrastructure using AWS services. This infrastructure will be capable of running penetration testing workflows by logging into AWS via the first exploited device capable of running curl or wget commands. The key AWS services to be leveraged in this project include Lambda, Step Functions, DynamoDB, S3, EC2, IAM, SageMaker, and Cloud9.

## Developer Notes

### Approach
As a data scientist, the goal is to develop this entire project using Python and/or AWS CLI. The development process is divided into several key steps:

#### Determine Functions Needed
Identify and list all the necessary functions that need to be implemented for successful remote pentesting. These functions could include, but are not limited to, network scanning, vulnerability scanning, exploitation, post-exploitation activities, and reporting.

#### Classify Functions
After the necessary functions have been identified, classify them based on their role within the pentesting workflow. For instance, some functions might be classified as reconnaissance functions, others as exploitation functions, etc.

#### Write Functions
Develop the necessary functions in Python or AWS CLI. Ensure each function is thoroughly tested and documented.

#### Write Schema
Create a schema that defines how data will be structured within DynamoDB. This schema should be designed to efficiently support the pentesting functions and workflows.

#### Write Mutations
Develop the necessary GraphQL mutations to create, update, or delete data within DynamoDB in accordance with the defined schema.

#### Write Resolvers
Implement the resolvers for the GraphQL API, ensuring that each query and mutation correctly interacts with the DynamoDB data.

## AWS Notes

### Building the Infrastructure
The AWS infrastructure will be designed to support the pentesting functions and APIs. Key steps in building this infrastructure will include:

1. **Setting up the AWS Services**: Configure the necessary AWS services (Lambda, Step Functions, DynamoDB, S3, EC2, IAM, SageMaker, Cloud9) to support the pentesting functions and workflows. This includes setting up IAM roles and policies, configuring Lambda functions and Step Functions workflows, setting up S3 buckets, and setting up DynamoDB tables in accordance with the defined schema.

2. **Setting up the API Gateway**: Configure AWS API Gateway to expose the pentesting functions as HTTP endpoints, allowing them to be triggered via curl or wget commands from the exploited device.

3. **Setting up the GraphQL API**: Implement the GraphQL API using AWS AppSync. This includes setting up the schema, implementing the resolvers, and configuring the data sources.

4. **Setting up SageMaker**: If necessary, set up AWS SageMaker for running Jupyter notebooks for analysis and reporting.

5. **Setting up Cloud9**: If necessary, set up AWS Cloud9 as a cloud-based integrated development environment for writing, running, and debugging the Python code.

Throughout the development process, ensure that all AWS resources are configured to adhere to best practices for security, scalability, and cost-effectiveness.

---

# Generate a structure

Here's a simplified tree structure for your project, along with the corresponding Python scripts that could be used to execute each stage:

```
|-- Project Root
    |-- README.md
    |-- requirements.txt
    |-- setup.py
    |-- notebooks
    |   |-- data_analysis.ipynb
    |   |-- pentesting_workflow.ipynb
    |-- src
        |-- __init__.py
        |-- reconnaissance
        |   |-- __init__.py
        |   |-- scan_network.py
        |   |-- enumerate_services.py
        |-- vulnerability_assessment
        |   |-- __init__.py
        |   |-- vulnerability_scan.py
        |   |-- vulnerability_analysis.py
        |-- exploitation
        |   |-- __init__.py
        |   |-- exploit_vulnerabilities.py
        |-- post_exploitation
        |   |-- __init__.py
        |   |-- gather_evidence.py
        |   |-- clean_up.py
        |-- reporting
            |-- __init__.py
            |-- generate_report.py
```

In the above project structure:

1. **`reconnaissance`**: This module contains scripts for the reconnaissance phase, including network scanning (`scan_network.py`) and service enumeration (`enumerate_services.py`).

2. **`vulnerability_assessment`**: This module includes scripts for the vulnerability assessment phase, including vulnerability scanning (`vulnerability_scan.py`) and vulnerability analysis (`vulnerability_analysis.py`).

3. **`exploitation`**: This module has scripts for the exploitation phase, specifically for exploiting identified vulnerabilities (`exploit_vulnerabilities.py`).

4. **`post_exploitation`**: This module contains scripts for post-exploitation activities, such as gathering evidence (`gather_evidence.py`) and cleaning up (`clean_up.py`).

5. **`reporting`**: This module has a script for generating the final report (`generate_report.py`).

6. **`notebooks`**: This directory contains Jupyter notebooks that can be used to execute the scripts and visualize the results. For example, the `pentesting_workflow.ipynb` notebook could contain code to execute the Python scripts in the correct order, while the `data_analysis.ipynb` notebook could be used for more in-depth analysis of the results.

Each script is modular and can be executed independently from the notebooks. This allows for a flexible workflow where different parts of the pentesting process can be executed separately as needed. 

Please note that the exact structure and content of your project might differ based on your specific requirements and workflows.

---

Sure, here's a Python script that will generate the filesystem structure described above, checking for the existence of each directory and file before creating it:

```python
import os

# Define the directory structure
dirs = [
    "notebooks",
    os.path.join("src", "reconnaissance"),
    os.path.join("src", "vulnerability_assessment"),
    os.path.join("src", "exploitation"),
    os.path.join("src", "post_exploitation"),
    os.path.join("src", "reporting"),
]

# Define the files in each directory
files = {
    "": ["README.md", "requirements.txt", "setup.py"],
    "notebooks": ["data_analysis.ipynb", "pentesting_workflow.ipynb"],
    os.path.join("src", "reconnaissance"): ["__init__.py", "scan_network.py", "enumerate_services.py"],
    os.path.join("src", "vulnerability_assessment"): ["__init__.py", "vulnerability_scan.py", "vulnerability_analysis.py"],
    os.path.join("src", "exploitation"): ["__init__.py", "exploit_vulnerabilities.py"],
    os.path.join("src", "post_exploitation"): ["__init__.py", "gather_evidence.py", "clean_up.py"],
    os.path.join("src", "reporting"): ["__init__.py", "generate_report.py"],
}

# Create each directory if it doesn't already exist
for dir in dirs:
    if not os.path.exists(dir):
        os.makedirs(dir)

# Create each file if it doesn't already exist
for dir, filenames in files.items():
    for filename in filenames:
        filepath = os.path.join(dir, filename)
        if not os.path.exists(filepath):
            with open(filepath, 'w') as f:
                pass  # Just create the file, don't write anything
```

This script will create the directories and files in the current working directory. Please note that it only creates empty files. You'll need to fill in the contents of each file yourself. 

Also, make sure to run this script in a directory where you have write permissions, and be careful not to overwrite any existing files or directories. You might want to run it in a new, empty directory to be safe.
